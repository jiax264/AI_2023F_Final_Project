{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f30f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import BallTree\n",
    "import copy\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204f5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fea675",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../00_Raw_Data/\"\n",
    "\n",
    "# Generate filenames from 2015_Q1 to 2022_Q4\n",
    "years = range(2015, 2023)\n",
    "quarters = range(1, 5)\n",
    "\n",
    "files = [\"{}_Q{}_Traffic_Crashes.csv\".format(year, quarter) for year in years for quarter in quarters]\n",
    "\n",
    "dfs = [pd.read_csv(folder + file) for file in files]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df[(df['longitude'] >= -87.05) & (df['longitude'] <= -86.5) & (df['latitude'] >= 35.96) & (df['latitude'] <= 36.395)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cd9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collision_date'] = pd.to_datetime(df['collision_date'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df['date'] = df['collision_date'].dt.date\n",
    "\n",
    "df['day_of_week'] = df['collision_date'].dt.dayofweek # 0: Monday - 6: Sunday\n",
    "\n",
    "df['time'] = df['collision_date'].dt.time\n",
    "df['hour'] = df['collision_date'].dt.hour\n",
    "df['month'] = df['collision_date'].dt.month\n",
    "df['year'] = df['collision_date'].dt.year\n",
    "df['covid'] = (df['date'] >= pd.Timestamp('2020-03-15').date()).astype(int)\n",
    "\n",
    "def categorize_time_window(hour):\n",
    "    if 6 <= hour <= 9:\n",
    "        return 'rush_morning'\n",
    "    elif 15 <= hour <= 18:\n",
    "        return 'rush_evening'\n",
    "    elif 10 <= hour <= 14:\n",
    "        return 'non_rush_day'\n",
    "    else:  \n",
    "        return 'non_rush_night'\n",
    "\n",
    "df['time_window'] = df['hour'].apply(categorize_time_window)\n",
    "\n",
    "columns_to_convert = ['pedestrian', 'bicycle', 'scooter', 'hitrun', 'parking']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].map({'yes': 1, 'no': 0})\n",
    "    \n",
    "df['manner_of_crash'] = df['manner_of_crash'].fillna('Unknown/Missing')\n",
    "df['manner_of_crash'] = df['manner_of_crash'].replace(['Missing', 'Unknown'], 'Unknown/Missing')\n",
    "crash_onehot = pd.get_dummies(df['manner_of_crash'], prefix='crash')\n",
    "df = pd.concat([df, crash_onehot], axis=1)\n",
    "df.drop('manner_of_crash', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "top_10_roads = df['roadway_name'].value_counts().head(10).index\n",
    "\n",
    "df['roadway_grouped'] = np.where(df['roadway_name'].isin(top_10_roads), df['roadway_name'], 'Other')\n",
    "\n",
    "roadway_onehot = pd.get_dummies(df['roadway_grouped'], prefix='road')\n",
    "df = pd.concat([df, roadway_onehot], axis=1)\n",
    "df.drop('roadway_grouped', axis=1, inplace=True)\n",
    "df.drop('roadway_name', axis=1, inplace=True)\n",
    "\n",
    "df['intersect_type'].replace(['OTHER', 'Missing', 'Unknown'], 'Unknown/Other', inplace=True)\n",
    "intersect_type_onehot = pd.get_dummies(df['intersect_type'], prefix='intersect_type')\n",
    "df = pd.concat([df, intersect_type_onehot], axis=1)\n",
    "df.drop('intersect_type', axis=1, inplace=True)\n",
    "\n",
    "df['relation_to_junction'].replace(['Missing', 'OtherLocation', 'Unknown'], 'Unknown/Other', inplace=True)\n",
    "relation_onehot = pd.get_dummies(df['relation_to_junction'], prefix='relation_to_junction')\n",
    "df = pd.concat([df, relation_onehot], axis=1)\n",
    "df.drop('relation_to_junction', axis=1, inplace=True)\n",
    "\n",
    "df.drop('city', axis=1, inplace=True)\n",
    "\n",
    "df['intersection_indicator'] = df['intersection_indicator'].fillna(\"N\")\n",
    "df['intersection_indicator'].replace(\"Missing\", \"N\", inplace=True)\n",
    "mapping = {\"N\": 0, \"Y\": 1}\n",
    "df['intersection_indicator'] = df['intersection_indicator'].map(mapping)\n",
    "df['intersection_indicator'] = df['intersection_indicator'].astype('int64')\n",
    "\n",
    "# Combine \"Campus\" and \"OHO\" categories\n",
    "df['mou'] = df['mou'].replace('OHO', 'Campus')\n",
    "\n",
    "# Now, encode \"Campus\" as 1 and \"False\" as 0\n",
    "df['mou'] = df['mou'].apply(lambda x: 1 if x == 'Campus' else 0)\n",
    "\n",
    "df['work_zone_type'] = df['work_zone_type'].fillna('Missing')\n",
    "df['work_zone_type'] = df['work_zone_type'].apply(lambda x: 0 if x == \"Missing\" or x == \"Unknown\" or x is None else 1)\n",
    "\n",
    "def simplify_weather(weather):\n",
    "    if pd.isna(weather):\n",
    "        return 'Unknown/Other'\n",
    "    elif 'Snow' in weather:\n",
    "        return 'Snow'\n",
    "    elif 'Sleet/Hail' in weather:\n",
    "        return 'Sleet/Hail'\n",
    "    elif 'Rain' in weather:\n",
    "        return 'Rain'\n",
    "    elif weather in ['Fog', 'Smoke', 'Smog']:\n",
    "        return 'Fog'\n",
    "    elif 'Cloudy' in weather:\n",
    "        return 'Cloudy'\n",
    "    elif weather == 'Clear':\n",
    "        return 'Clear'\n",
    "    elif weather in ['Missing', 'Unknown', 'Other']:\n",
    "        return 'Unknown/Other'\n",
    "    else:\n",
    "        return 'Other Conditions'\n",
    "\n",
    "df['simplified_weather'] = df['weather_condition(s)'].apply(simplify_weather)\n",
    "df = pd.get_dummies(df, columns=['simplified_weather'], prefix='weather')\n",
    "df.drop('weather_condition(s)', axis=1, inplace=True)\n",
    "\n",
    "def bool_to_int(df):\n",
    "    for col in df.select_dtypes(['bool']).columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    return df\n",
    "\n",
    "df = bool_to_int(df)\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"agency\", \"agency_tracking_number\", \"county\", \n",
    "    \"collision_date\", \"roadway_suffix\", \"roadway_number\", \"roadway_local_id\", \n",
    "    \"distance_from_reference\", \"miles-feet_indicator\", \"direction_from_reference\",\n",
    "    \"intersection_road_name\", \"intersection_road_name_suffix\", \"intersection_road_number\",\n",
    "    \"intersection_local_id\", \"mile_marker\", \"interchange_related_indicator\", \n",
    "    \"construction_maintenance_zone\", \"construction_maintenance_zone_location\",\n",
    "    \"fatal_case_number\", \"date\", \"officer_first_name\", \"officer_last_name\", 'scooter'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b98585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = df['time'].astype(str)\n",
    "df['time'] = df['time'].str.strip()\n",
    "has_time = df[df['time'] != \"00:00:00\"]\n",
    "has_time = has_time.drop('time', axis=1)\n",
    "\n",
    "\n",
    "weekday_df = has_time[has_time['day_of_week'].between(0, 4)].copy()  \n",
    "weekday_df = weekday_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "time_window_mapping = {\n",
    "    'rush_morning': 0,\n",
    "    'rush_evening': 1,\n",
    "    'non_rush_day': 2,\n",
    "    'non_rush_night': 3\n",
    "}\n",
    "\n",
    "weekday_df['time_window'] = weekday_df['time_window'].replace(time_window_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf5da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_time_df = copy.deepcopy(weekday_df)\n",
    "\n",
    "train_val, test = train_test_split(has_time_df, test_size=0.1, stratify=has_time_df['time_window'], random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=2/9, stratify=train_val['time_window'], random_state=42)\n",
    "\n",
    "tree = BallTree(train[['latitude', 'longitude']].values)\n",
    "\n",
    "k_value = 4 \n",
    "\n",
    "def calculate_mode_time_window_of_nearest(train_tree, train_data_with_coords, point, k=k_value):\n",
    "    # Query the BallTree for k+1 nearest neighbors\n",
    "    dist, ind = train_tree.query(point, k=k + 1)\n",
    "    neighbors_indices = ind[0]\n",
    "\n",
    "    # Fetch the neighbors from the training data using indices\n",
    "    neighbors = train_data_with_coords.iloc[neighbors_indices]\n",
    "\n",
    "    # Check if the first neighbor is the point itself\n",
    "    point_series = pd.Series(point.flatten(), index=['latitude', 'longitude'])\n",
    "    if (neighbors.head(1)[['latitude', 'longitude']] == point_series).all(axis=1).any():\n",
    "        neighbors = neighbors.iloc[1:]  # Exclude the first neighbor\n",
    "    else:\n",
    "        neighbors = neighbors.iloc[:k]  # Keep only the first k neighbors\n",
    "\n",
    "    # Extract 'time_window' from the neighbors DataFrame\n",
    "    time_windows = neighbors['time_window']\n",
    "\n",
    "    # Check if there are enough neighbors\n",
    "    if len(time_windows) < k:\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate the mode of the 'time_window'\n",
    "    mode_result = mode(time_windows)\n",
    "    modes = mode_result.mode\n",
    "\n",
    "    # Handle the mode results\n",
    "    if modes.size == 0:  # No mode found\n",
    "        return np.nan\n",
    "    elif modes.size > 1:  # Handle ties by selecting a random mode\n",
    "        return random.choice(modes)\n",
    "    else:\n",
    "        return modes.item()\n",
    "    \n",
    "train_data_with_coords = train[['latitude', 'longitude', 'time_window']]    \n",
    "has_time_df['most_common_time_window_{}_neigh'.format(k_value)] = has_time_df.apply(\n",
    "    lambda row: calculate_mode_time_window_of_nearest(\n",
    "        tree, \n",
    "        train_data_with_coords,  \n",
    "        np.array([[row['latitude'], row['longitude']]]),\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_with_avg_hour = has_time_df.set_index('master_record_number')[['most_common_time_window_{}_neigh'.format(k_value)]]\n",
    "\n",
    "train_with_avg_hour = train.set_index('master_record_number').join(df_with_avg_hour)\n",
    "val_with_avg_hour = val.set_index('master_record_number').join(df_with_avg_hour)\n",
    "test_with_avg_hour = test.set_index('master_record_number').join(df_with_avg_hour)\n",
    "\n",
    "train_with_avg_hour = train_with_avg_hour.reset_index()\n",
    "val_with_avg_hour = val_with_avg_hour.reset_index()\n",
    "test_with_avg_hour = test_with_avg_hour.reset_index()\n",
    "\n",
    "train_xgboost = train_with_avg_hour.drop(['hour', 'master_record_number'], axis=1).copy()\n",
    "val_xgboost = val_with_avg_hour.drop(['hour', 'master_record_number'], axis=1).copy()\n",
    "test_xgboost = test_with_avg_hour.drop(['hour', 'master_record_number'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fc3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xgboost.to_csv(\"../03_Data_for_Modeling/train_xgboost.csv\", index=False)\n",
    "val_xgboost.to_csv(\"../03_Data_for_Modeling/val_xgboost.csv\", index=False)\n",
    "test_xgboost.to_csv(\"../03_Data_for_Modeling/test_xgboost.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalproj",
   "language": "python",
   "name": "finalproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
