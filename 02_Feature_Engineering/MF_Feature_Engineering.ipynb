{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb84a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fancyimpute import MatrixFactorization\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import BallTree\n",
    "from fancyimpute import MatrixFactorization\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da3aecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d92534f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../00_Raw_Data/\"\n",
    "\n",
    "# Generate filenames from 2015_Q1 to 2022_Q4\n",
    "years = range(2015, 2023)\n",
    "quarters = range(1, 5)\n",
    "\n",
    "files = [\"{}_Q{}_Traffic_Crashes.csv\".format(year, quarter) for year in years for quarter in quarters]\n",
    "\n",
    "dfs = [pd.read_csv(folder + file) for file in files]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df[(df['longitude'] >= -87.05) & (df['longitude'] <= -86.5) & (df['latitude'] >= 35.96) & (df['latitude'] <= 36.395)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a67c41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['collision_date'] = pd.to_datetime(df['collision_date'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "df['date'] = df['collision_date'].dt.date\n",
    "\n",
    "df['day_of_week'] = df['collision_date'].dt.dayofweek # 0: Monday - 6: Sunday\n",
    "\n",
    "df['time'] = df['collision_date'].dt.time\n",
    "df['hour'] = df['collision_date'].dt.hour\n",
    "df['day_of_month'] = df['collision_date'].dt.day\n",
    "df['month'] = df['collision_date'].dt.month\n",
    "df['year'] = df['collision_date'].dt.year\n",
    "df['covid'] = (df['date'] >= pd.Timestamp('2020-03-15').date()).astype(int)\n",
    "\n",
    "def categorize_time_window(hour):\n",
    "    if 6 <= hour <= 9:\n",
    "        return 'rush_morning'\n",
    "    elif 15 <= hour <= 18:\n",
    "        return 'rush_evening'\n",
    "    elif 10 <= hour <= 14:\n",
    "        return 'non_rush_day'\n",
    "    else:  \n",
    "        return 'non_rush_night'\n",
    "\n",
    "df['time_window'] = df['hour'].apply(categorize_time_window)\n",
    "\n",
    "\n",
    "columns_to_convert = ['pedestrian', 'bicycle', 'scooter', 'hitrun', 'parking']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df[column] = df[column].map({'yes': 1, 'no': 0})\n",
    "    \n",
    "    \n",
    "df['manner_of_crash'] = df['manner_of_crash'].fillna('Unknown/Missing')\n",
    "df['manner_of_crash'] = df['manner_of_crash'].replace(['Missing', 'Unknown'], 'Unknown/Missing')\n",
    "crash_onehot = pd.get_dummies(df['manner_of_crash'], prefix='crash')\n",
    "df = pd.concat([df, crash_onehot], axis=1)\n",
    "df.drop('manner_of_crash', axis=1, inplace=True)\n",
    "\n",
    "df.drop('roadway_name', axis=1, inplace=True)\n",
    "\n",
    "df['intersect_type'].replace(['OTHER', 'Missing', 'Unknown'], 'Unknown/Other', inplace=True)\n",
    "intersect_type_onehot = pd.get_dummies(df['intersect_type'], prefix='intersect_type')\n",
    "df = pd.concat([df, intersect_type_onehot], axis=1)\n",
    "df.drop('intersect_type', axis=1, inplace=True)\n",
    "\n",
    "df['relation_to_junction'].replace(['Missing', 'OtherLocation', 'Unknown'], 'Unknown/Other', inplace=True)\n",
    "relation_onehot = pd.get_dummies(df['relation_to_junction'], prefix='relation_to_junction')\n",
    "df = pd.concat([df, relation_onehot], axis=1)\n",
    "df.drop('relation_to_junction', axis=1, inplace=True)\n",
    "\n",
    "df.drop('city', axis=1, inplace=True)\n",
    "\n",
    "df['intersection_indicator'] = df['intersection_indicator'].fillna(\"N\")\n",
    "df['intersection_indicator'].replace(\"Missing\", \"N\", inplace=True)\n",
    "mapping = {\"N\": 0, \"Y\": 1}\n",
    "df['intersection_indicator'] = df['intersection_indicator'].map(mapping)\n",
    "df['intersection_indicator'] = df['intersection_indicator'].astype('int64')\n",
    "\n",
    "# Combine \"Campus\" and \"OHO\" categories\n",
    "df['mou'] = df['mou'].replace('OHO', 'Campus')\n",
    "\n",
    "# Now, encode \"Campus\" as 1 and \"False\" as 0\n",
    "df['mou'] = df['mou'].apply(lambda x: 1 if x == 'Campus' else 0)\n",
    "\n",
    "df['work_zone_type'] = df['work_zone_type'].fillna('Missing')\n",
    "df['work_zone_type'] = df['work_zone_type'].apply(lambda x: 0 if x == \"Missing\" or x == \"Unknown\" or x is None else 1)\n",
    "\n",
    "\n",
    "def simplify_weather(weather):\n",
    "    if pd.isna(weather):\n",
    "        return 'Unknown/Other'\n",
    "    elif 'Snow' in weather:\n",
    "        return 'Snow'\n",
    "    elif 'Sleet/Hail' in weather:\n",
    "        return 'Sleet/Hail'\n",
    "    elif 'Rain' in weather:\n",
    "        return 'Rain'\n",
    "    elif weather in ['Fog', 'Smoke', 'Smog']:\n",
    "        return 'Fog'\n",
    "    elif 'Cloudy' in weather:\n",
    "        return 'Cloudy'\n",
    "    elif weather == 'Clear':\n",
    "        return 'Clear'\n",
    "    elif weather in ['Missing', 'Unknown', 'Other']:\n",
    "        return 'Unknown/Other'\n",
    "    else:\n",
    "        return 'Other Conditions'\n",
    "\n",
    "df['simplified_weather'] = df['weather_condition(s)'].apply(simplify_weather)\n",
    "df = pd.get_dummies(df, columns=['simplified_weather'], prefix='weather')\n",
    "df.drop('weather_condition(s)', axis=1, inplace=True)\n",
    "\n",
    "def bool_to_int(df):\n",
    "    for col in df.select_dtypes(['bool']).columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    return df\n",
    "\n",
    "df = bool_to_int(df)\n",
    "\n",
    "df['time'] = df['time'].astype(str)\n",
    "df['time'] = df['time'].str.strip()\n",
    "has_time_df = df[df['time'] != \"00:00:00\"]\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"agency\", \"agency_tracking_number\", \"county\", \n",
    "    \"collision_date\", \"roadway_suffix\", \"roadway_number\", \"roadway_local_id\", \n",
    "    \"distance_from_reference\", \"miles-feet_indicator\", \"direction_from_reference\",\n",
    "    \"intersection_road_name\", \"intersection_road_name_suffix\", \"intersection_road_number\",\n",
    "    \"intersection_local_id\", \"mile_marker\", \"interchange_related_indicator\", \n",
    "    \"construction_maintenance_zone\", \"construction_maintenance_zone_location\",\n",
    "    \"fatal_case_number\", \"date\", \"officer_first_name\", \"officer_last_name\", \"time\"\n",
    "]\n",
    "\n",
    "has_time_df = has_time_df.drop(columns=columns_to_drop)\n",
    "weekday_df = has_time_df[has_time_df['day_of_week'].between(0, 4)].copy()  \n",
    "\n",
    "weekday_df = weekday_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "time_window_mapping = {\n",
    "    'rush_morning': 0,\n",
    "    'rush_evening': 1,\n",
    "    'non_rush_day': 2,\n",
    "    'non_rush_night': 3\n",
    "}\n",
    "\n",
    "weekday_df['time_window'] = weekday_df['time_window'].replace(time_window_mapping)\n",
    "scaler = MinMaxScaler()\n",
    "weekday_df[['latitude', 'longitude']] = scaler.fit_transform(weekday_df[['latitude', 'longitude']])\n",
    "\n",
    "selected_cols = ['master_record_number', 'latitude', 'longitude', 'intersection_indicator', 'hitrun', 'parking', 'hour', 'vehicles_involved', \n",
    "                 'day_of_week', 'month', 'number_injured', 'number_dead', 'covid', 'time_window']\n",
    "\n",
    "has_time_df = weekday_df[selected_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d29a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(has_time_df, test_size=0.1, stratify=has_time_df['time_window'], random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=2/9, stratify=train_val['time_window'], random_state=42)\n",
    "\n",
    "# Create a BallTree using the training data\n",
    "tree = BallTree(train[['latitude', 'longitude']].values)\n",
    "\n",
    "# Function to calculate average hour of the four closest neighbors from the training set\n",
    "def calculate_avg_hour_of_nearest(train_tree, train_data, point, k=4):\n",
    "    dist, ind = train_tree.query(point, k=k)\n",
    "    # Handle cases with fewer than k neighbors\n",
    "    if len(train_data.iloc[ind[0]]) < k:  \n",
    "        return np.nan\n",
    "    return train_data.iloc[ind[0]]['hour'].mean()\n",
    "\n",
    "# Calculate the 'avg_hour_4_neigh' for the training set\n",
    "has_time_df['avg_hour_4_neigh'] = has_time_df.apply(\n",
    "    lambda row: calculate_avg_hour_of_nearest(\n",
    "        tree, \n",
    "        train[['hour']], \n",
    "        np.array([[row['latitude'], row['longitude']]])\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_with_avg_hour = has_time_df.set_index('master_record_number')[['avg_hour_4_neigh']]\n",
    "\n",
    "# Merge 'avg_hour_4_neigh' into the original train, validation, and test sets using 'master_record_number'\n",
    "train_with_avg_hour = train.set_index('master_record_number').join(df_with_avg_hour)\n",
    "val_with_avg_hour = val.set_index('master_record_number').join(df_with_avg_hour)\n",
    "test_with_avg_hour = test.set_index('master_record_number').join(df_with_avg_hour)\n",
    "\n",
    "# Reset the index if required to bring 'master_record_number' back to columns\n",
    "train_with_avg_hour = train_with_avg_hour.reset_index()\n",
    "val_with_avg_hour = val_with_avg_hour.reset_index()\n",
    "test_with_avg_hour = test_with_avg_hour.reset_index()\n",
    "\n",
    "train_with_avg_hour = train_with_avg_hour.drop(['master_record_number','time_window'], axis=1).copy()\n",
    "val_with_avg_hour = val_with_avg_hour.drop(['master_record_number','time_window'], axis=1).copy()\n",
    "test_with_avg_hour = test_with_avg_hour.drop(['master_record_number','time_window'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fef8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_avg_hour.to_csv(\"../03_Data_for_Modeling/train_matrix_factorization_new_time_window.csv\", index=False)\n",
    "val_with_avg_hour.to_csv(\"../03_Data_for_Modeling/val_matrix_factorization_new_time_window.csv\", index=False)\n",
    "test_with_avg_hour.to_csv(\"../03_Data_for_Modeling/test_matrix_factorization_new_time_window.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalproj",
   "language": "python",
   "name": "finalproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
